{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13a5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19bbdbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest articles in python section:\n",
      "1.Python 3.13.0 alpha 1 is now available\n",
      "2.Python 3.11.6 is now available\n",
      "3.Python 3.12.0 (final) now available\n",
      "4.Python Developers Survey Numbers for 2022!\n",
      "5.Python 3.12.0 release candidate 3 now available\n",
      "no article found\n"
     ]
    }
   ],
   "source": [
    "# scrapping the latest python articles\n",
    "def latest_python_article():\n",
    "    url = 'https://www.python.org/'\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        latest_article = []\n",
    "        \n",
    "        for article in soup.select(\".blog-widget li\"):\n",
    "            title = article.a.text.strip()\n",
    "            latest_article.append(title)\n",
    "        return latest_article\n",
    "    else:\n",
    "        print(f\"failed to retrieve data.status code:{r.status_code}\")\n",
    "        return []\n",
    "if __name__==\"__main__\":\n",
    "    python_articles = latest_python_article()\n",
    "    \n",
    "    if python_articles:\n",
    "        print('latest articles in python section:')\n",
    "        for index,article in enumerate(python_articles,1):\n",
    "            print(f\"{index}.{article}\")\n",
    "        else:\n",
    "            print(\"no article found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b569506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequency on python.org website is:\n",
      "python:64\n",
      "the:23\n",
      "and:21\n",
      "3:18\n",
      "to:16\n",
      "for:16\n",
      "2023:15\n",
      "a:14\n",
      "is:13\n",
      "of:11\n",
      "news:11\n",
      "events:11\n",
      "more:11\n",
      "s:10\n",
      "community:9\n",
      "in:9\n",
      "with:8\n",
      "psf:8\n",
      "0:8\n",
      "10:8\n",
      "docs:7\n",
      "1:7\n",
      "other:6\n",
      "guide:6\n",
      "lists:6\n",
      "software:6\n",
      "print:6\n",
      "product:6\n",
      "available:6\n",
      "about:5\n",
      "code:5\n",
      "stories:5\n",
      "development:5\n",
      "2:5\n",
      "functions:5\n",
      "list:5\n",
      "learn:5\n",
      "your:4\n",
      "all:4\n",
      "developer:4\n",
      "user:4\n",
      "group:4\n",
      "archive:4\n",
      "n:4\n",
      "b:4\n",
      "5:4\n",
      "programming:4\n",
      "are:4\n",
      "that:4\n",
      "simple:4\n",
      "you:4\n",
      "name:4\n",
      "language:4\n",
      "now:4\n",
      "org:3\n",
      "while:3\n",
      "be:3\n",
      "on:3\n",
      "jobs:3\n",
      "irc:3\n",
      "started:3\n",
      "help:3\n",
      "source:3\n",
      "documentation:3\n",
      "beginner:3\n",
      "diversity:3\n",
      "report:3\n",
      "get:3\n",
      "success:3\n",
      "scientific:3\n",
      "pycon:3\n",
      "us:3\n",
      "from:3\n",
      "submit:3\n",
      "an:3\n",
      "8:3\n",
      "13:3\n",
      "21:3\n",
      "fruits:3\n",
      "banana:3\n",
      "apple:3\n",
      "lime:3\n",
      "data:3\n",
      "can:3\n",
      "work:3\n",
      "numbers:3\n",
      "flow:3\n",
      "easy:3\n",
      "our:3\n",
      "12:3\n",
      "foundation:3\n",
      "javascript:2\n",
      "this:2\n",
      "website:2\n",
      "content:2\n",
      "donate:2\n",
      "go:2\n",
      "applications:2\n",
      "quotes:2\n",
      "getting:2\n"
     ]
    }
   ],
   "source": [
    "def get_webpage_text(url):\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        text = ' '.join(soup.stripped_strings)\n",
    "        return text\n",
    "    else:\n",
    "        print(f\"failed to retrieve data.status code:{r.status_code}\")\n",
    "        return \"\"\n",
    "    \n",
    "def get_word_frequency(text):\n",
    "    words = re.findall(r'\\w+',text.lower())\n",
    "    word_count = Counter(words)\n",
    "    return word_count\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    url = 'https://www.python.org/'\n",
    "    webpage_text = get_webpage_text(url)\n",
    "    \n",
    "    if webpage_text:\n",
    "        word_frequency = get_word_frequency(webpage_text)\n",
    "        print('Word frequency on python.org website is:')\n",
    "        for word,frequency in word_frequency.most_common(100):\n",
    "            print(f\"{word}:{frequency}\")\n",
    "    else:\n",
    "        print(\"failed to count word frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfd71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
